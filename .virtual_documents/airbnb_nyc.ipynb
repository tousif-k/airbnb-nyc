import numpy as np
import pandas as pd
import seaborn as sns
sns.set(style="ticks", color_codes=True)
import matplotlib as mpl
import matplotlib.pyplot as plt


file = 'datasets/listings.csv'
df = pd.read_csv(file)
df


df.dtypes


df.isnull().sum()


df.fillna({'reviews_per_month':0}, inplace=True)
df.fillna({'name':'noname'}, inplace=True)
df.fillna({'host_name':'noname'}, inplace=True)
df.fillna({'last_review':'noreviews'}, inplace=True)


df.isnull().sum()


 df['price'].describe()


hist_price = df['price'].hist()


hist_price = df['price'][df.price < 1000].hist()


df[df.price > 1000]


df_ex = df[df.price >= 1000] # all the expensive listings, which is skewing the dataset
df = df[df.price < 1000] # will now be the main dataset


hist_price = df['price'][df.price < 250].hist()


df_ex2 = df[df.price >= 250]
df = df[df.price < 250]
df['price'].describe()


df['neighbourhood'].value_counts()


df_nh = df.groupby('neighbourhood').filter(lambda x: x['neighbourhood'].count() > 200)


len(df_nh['neighbourhood'])


df_nh = df.groupby('neighbourhood').filter(lambda x: x['neighbourhood'].count() == 1)
len(df_nh.neighbourhood)


df.neighbourhood_group.value_counts()


ng_price = df.groupby('neighbourhood_group')['price'].mean()
ng_price


plott = sns.catplot(x='neighbourhood_group', y='price', hue='room_type', kind='swarm', data=df)
plott


df_hosts = df.groupby(['host_id'])
max(df_hosts.size())


df_hosts.size().value_counts().head()


df_hosts.size().value_counts().tail()


host_id_counts = df['host_id'].value_counts()
max_host = host_id_counts.idxmax()
max_host


df[df['host_id'] == max_host]


df = df.drop(columns=['id', 'host_name']) # not too useful
df['name_length'] = df['name'].map(str).apply(len)


print(df['name_length'].max())
print(df['name_length'].min())
print(df['name_length'].idxmax())
print(df['name_length'].idxmin())


df.at[35555, 'name']


df.at[6959, 'name']


df.plot.scatter(x='name_length', y='number_of_reviews') # seeing if theres a relationship between name length and popularity (measured by # of reviews)


df[df['name_length'] < 50].plot.scatter(x='price', y='name_length')


df.name_length.hist()


df['room_type'].value_counts()


rt_price = df.groupby('room_type')['price'].mean()


rt_price


df['minimum_nights'].describe()


hist_mn = df['minimum_nights'].hist()
hist_mn


hist_mn1 = df['minimum_nights'][df.minimum_nights < 10].hist()
hist_mn1


df['minimum_nights'][df.minimum_nights > 30]


df.loc[(df.minimum_nights > 30), 'minimum_nights']=30


hist_mn2 = df['minimum_nights'][df.minimum_nights < 30].hist()
hist_mn2


df['minimum_nights'].corr(df['price'])


df['availability_365'].describe()


hist_av = df['availability_365'].hist()
hist_av


df.drop(['name', 'last_review', 'latitude', 'longitude'], axis=1, inplace=True)


df.drop(['host_id'], axis=1, inplace=True)


corr = df.corr(method='pearson')
plt.figure(figsize=(15,8))
sns.heatmap(corr, annot=True)
df.columns


df.dtypes


oh1 = pd.get_dummies(df, columns=['neighbourhood_group', 'room_type'], prefix=['ng', 'rt'], drop_first=True)
oh1.drop(['neighbourhood'], axis=1, inplace=True)
oh1.shape


X1 = oh1.loc[:, oh1.columns != 'price']
Y1 = oh1['price']


from sklearn import preprocessing, metrics
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split


x_train1, x_test1, y_train1, y_test1 = train_test_split(X1, Y1, test_size=0.20, random_state=72)


reg1 = LinearRegression().fit(x_train1, y_train1)


reg1.score(x_train1, y_train1)


reg1.coef_


y_pred1 = reg1.predict(x_test1)


Coeff1 = pd.DataFrame(columns=['Variable', 'Coefficient'])
Coeff1['Variable'] = x_train1.columns
Coeff1['Coefficient'] = reg1.coef_
Coeff1.sort_values('Coefficient')


rmse1 = np.sqrt(metrics.mean_squared_error(y_test1, y_pred1))
rmse1


import statsmodels.api as sm


X2 = sm.add_constant(x_train1)
est = sm.OLS(y_train1, X2)
est2 = est.fit()
est2.summary()


# Number of reviews and ng_Staten Island are not significant
x_train1.drop(['number_of_reviews', 'ng_Staten Island'], axis=1, inplace=True)
X2 = sm.add_constant(x_train1)
est = sm.OLS(y_train1, X2)
est2 = est.fit()
est2.summary()


df_onehot2 = pd.get_dummies(df, columns=['neighbourhood_group', 'neighbourhood', 'room_type'], prefix=['ng', 'nh', 'rt'], drop_first=True)
df_onehot2.shape


XL1 = df_onehot2.loc[:, df_onehot2.columns != 'price']
YL1 = df_onehot2['price']
x_trainL11, x_testL11, y_trainL11, y_testL11 = train_test_split(XL1, YL1, test_size=0.20, random_state=42)


# Using Lasso regression


regL1 = Lasso(alpha=0.01)
regL1.fit(x_trainL11, y_trainL11)


regL1.score(x_trainL11, y_trainL11)


y_predL1 = regL1.predict(x_testL11)
print(np.sqrt(metrics.mean_squared_error(y_testL11, y_predL1)))


regL1.coef_


CoeffLS1 = pd.DataFrame(columns=['Variable', 'Coefficients'])
CoeffLS1['Variable']=x_trainL11.columns
CoeffLS1['Coefficients']=regL1.coef_
CoeffLS1.sort_values('Coefficients', ascending=False)


# Now trying Random forest regressor


regrRM = RandomForestRegressor(n_estimators=300)
regrRM.fit(x_trainL11, y_trainL11)


print(regrRM.score(x_trainL11, y_trainL11))
y_predL1 = regrRM.predict(x_testL11)
print(np.sqrt(metrics.mean_squared_error(y_testL11, y_predL1)))


regrRM.feature_importances_


CoeffRM2 = pd.DataFrame(columns=['Variable', 'FeatureImportance'])
CoeffRM2['Variable'] = x_trainL11.columns
CoeffRM2['FeatureImportance'] = regrRM.feature_importances_
CoeffRM2.sort_values('FeatureImportance', ascending=False)


regrRM.get_params()



